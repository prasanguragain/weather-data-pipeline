# ðŸŒ¦ï¸ Weather Data Pipeline

This project automates the **ingestion**, **transformation**, and **visualization** of weather data using a modern data stack:

- **Python API**: Fetches real-time weather via Weatherstack API  
- **PostgreSQL**: Stores raw weather data  
- **Airflow**: Orchestrates the ingestion and dbt processes as DAGs  
- **dbt**: Transforms & models raw data for analytics  
- **Superset**: Provides a BI dashboard to explore and visualize data  
- **Docker Compose**: Defines all services in a clean, reproducible setup

---

## ðŸ“ Repository Structure

```
weather-data-pipeline/
â”œâ”€â”€ api_request/              # Python modules: fetch & insert weather API data
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/
â”‚       â””â”€â”€ weather_api_orchestrator.py
â”œâ”€â”€ dbt/
â”‚   â”œâ”€â”€ my_project/           # dbt project
â”‚   â””â”€â”€ profiles.yml          # or symlink to ~/.dbt/profiles.yml
â”œâ”€â”€ postgres/                 # DB init scripts for Airflow & Superset
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ .env.example          # Sample env file (never commit secrets)
â”‚   â””â”€â”€ superset_config.py    # Superset config via Docker
â”œâ”€â”€ docker-compose.yml        # Orchestration of all services
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## âœ… Prerequisites

- Docker & Docker Compose  
- Python 3 (for running scripts outside Docker)  
- *(Optional)* dbt Core for local transformations  

---

## ðŸš€ Getting Started

1. Clone the repo  
   ```bash
   git clone https://github.com/prasanguragain/weather-data-pipeline.git
   cd weather-data-pipeline
   ```

2. Copy the `.env.example` to `.env` and add required secrets  
   ```bash
   cp docker/.env.example .env
   ```

3. Run all services using Docker Compose  
   ```bash
   docker-compose up --build
   ```

4. Access services:  
   - Airflow: [http://localhost:8080](http://localhost:8080)  
   - Superset: [http://localhost:8088](http://localhost:8088)  

5. Explore:  
   - Airflow DAG for orchestration  
   - Superset dashboard for weather insights  

---

## ðŸ§¹ Cleanup

To stop and remove all services and volumes:

```bash
docker-compose down -v
```

---

## ðŸ›  Development Tips

- Use `venv` and install requirements if testing scripts locally  
- Modify DAGs in `airflow/dags/`  
- Edit dbt models in `dbt/my_project/models/`  
- Customize Superset in `docker/superset_config.py`  

---

## ðŸ” Security & Best Practices

- Never commit secrets or API keys â€” use `.env` files  
- Add volumes, logs, etc., to `.gitignore`  
- Secure Superset, Airflow, and PostgreSQL for production deployments  

---

## ðŸ“ˆ Next Steps

- Add unit tests for Python scripts and dbt models  
- Set up CI/CD pipelines  
- Publish images to Docker Hub or GitHub Packages  

---

## ðŸ“œ License

MIT License  
Â© 2025 Prasan Guragain

> Permission is hereby granted, free of charge, to any person obtaining a copy  
> of this software and associated documentation files (the "Software"), to deal  
> in the Software without restriction...

*See the [LICENSE](./LICENSE) file for full details.*

---

## âœ¨ Enjoy building and visualizing weather insights!
